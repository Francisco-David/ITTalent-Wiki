<div style={{ display: 'flex' }}>
  <img src="/img/TalentLOGO.png" alt="Imagen 1" style={{ width: '50%', height: 'auto' }} />
  <img src="/img/USLOGO.png" alt="Imagen 2" style={{ width: '30%', height: '30%' }} />
</div>

## <center>Ingeniería del Software y Práctica Profesional - Universidad de Sevilla</center>

BERMEJO SORIA, CARLOS

CASAL FERRERO, RUBÉN

DOMÍNGUEZ RUIZ. ANDRÉS

DOMÍNGUEZ-ADAME RUIZ. ALBERTO

FERNÁNDEZ CASTILLO, JAVIER

GALLARDO MARTOS, DANIEL

HERRERA RAMIREZ, ISMAEL

IZQUIERDO LAVADO, MARIO

MATEOS GÓMEZ, FERNANDO JOSÉ

MERINO PALMA, ALEJANDRO JOSÉ

MONTERO MARTÍNEZ, FRANCISCO JESÚS

LÓPEZ MOYANO, ROCÍO

OTERO BARBASÁN, MANUEL

VILAPLANA DE TRÍAS, FRANCISCO DAVID

ZARZUELA REINA, CARLOS



### Entregable: S2
### Grupo 01 (Mañana) - IT Talent


# <a name="_z05qqri5g3tk"></a>Control de Versiones


|**Versión**|**Fecha**|**Autor**|**Cambios**|
| :- | :- | :- | :- |
|v1.0|8/02/24|Paco|Documento inicial|
|v1.1|13/02/24|Paco|Adición de contenido de la 2a semana|
|v1.2|20/02/24|Paco|Adición de contenido de la 3a semana|
|v1.3|27/02/24|Paco|Adición de contenido de la 4a semana|
|v1.4|05/03/24|Paco|Adición de contenido de la 5a semana|
|v1.5|21/03/24|Paco|Adición de contenido de la 7a semana|

## <a name="_lj1qgmxpo5ez"></a>**Resumen del documento**
<a name="_30j0zll"></a>En este documento se recoge todo el feedback semanal recibido por parte de profesores y alumnos el día de la presentación a cada uno de los grupos, el feedback para nuestro equipo y las tareas que no pueden faltar de una semana a otra

<a name="_b55u8w51bgk6"></a>
# <a name="_lzfi3azarw8p"></a>Índice

[1. Semana 1 (06/02)	3](#_3znysh7)

[Cosas a tener en cuenta	3](#_2et92p0)

[Consideraciones para IT TALENT	5](#_35xmkliq9lbp)

[Tareas	6](#_gwy715co0tk5)

[2. Semana 2 (13/02)	7](#_3n6nqs3ox56d)

[Cosas a tener en cuenta	7](#_4ki1iznv6aw6)

[Consideraciones para IT TALENT	9](#_es35wsm2my6q)

[Tareas - ¿Qué no puede faltar?	10](#_xw8pcxlaup9y)

[3. Semana 3 (20/02)	11](#_chp71xun2gc6)

[Cosas a tener en cuenta	11](#_jnimpmeuvwuu)

[Consideraciones para IT TALENT	12](#_o9sh85hrxn04)

[Tareas - ¿Qué no puede faltar?	13](#_hp9ikto9rfsy)

[4. Semana 4 (13/02)	15](#_at55to1wrtcp)

[Cosas a tener en cuenta	15](#_1n0ltkyakv2)

[Consideraciones para IT TALENT	17](#_k9wifui2ze97)

[Tareas - ¿Qué no puede faltar?	18](#_w1wwzt1pmvgj)

[5. Semana 7 (19/03)	](#_3n6nqs3ox56d2)

[Cosas a tener en cuenta	](#_4ki1iznv6aw62)

[Consideraciones para IT TALENT	](#_es35wsm2my6q2)

[Tareas - ¿Qué no puede faltar?	](#_xw8pcxlaup9y2)

[6. Semana 8 (02/04)	](#_3n6nqs3ox56d22)

[Cosas a tener en cuenta	](#_4ki1iznv6aw622)

[Consideraciones para IT TALENT	](#_es35wsm2my6q22)

[Tareas - ¿Qué no puede faltar?	](#_xw8pcxlaup9y22)

[7. Semana 9 (09/04)	](#_3n6nqs3ox56d23)

[Cosas a tener en cuenta	](#_4ki1iznv6aw623)

[Consideraciones para IT TALENT	](#_es35wsm2my6q23)

[Tareas - ¿Qué no puede faltar?	](#_xw8pcxlaup9y23)

[8. Semana 10 (23/04)	](#_3n6nqs3ox56d24)

[Cosas a tener en cuenta	](#_4ki1iznv6aw624)

[Consideraciones para IT TALENT	](#_es35wsm2my6q24)

[Tareas - ¿Qué no puede faltar?	](#_xw8pcxlaup9y24)




1. # <a name="_3znysh7"></a> Semana 1 (06/02) 
## <a name="_2et92p0"></a>**Cosas a tener en cuenta**

1. Presentaciones siempre preparadas para una **duración de 18 minutos**.
1. Durante las  presentaciones, en el último minuto del feedback del grupo exponiendo el encargado del siguiente debe ir preparando su presentación en el ordenador del aula.
1. Tener algún tipo de **moderación para estafas si procede** para asegurar la fiabilidad.
1. Se debe buscar una **exposición de conceptos lenta** para poder madurar lo que se va diciendo.
1. “**Segmentar las ideas**” de tal manera que queden claros los mensajes clave.
1. **Usar y plasmar las palabras** más **claves** (p.e: debilidades de la competencia) durante la presentación.
1. Es fundamental **tener establecido** el **TCO**, **TC puesta en marcha** y el **TC de mantenimiento** en el plan de manera **clara y concisa**.
1. Los **casos de uso de la aplicación**, deben estar claramente definidos.
1. Cuidar presentación: **Numeración, letras legibles** (cuidar fondos y tamaños)**, textos cortos y usar imágenes e iconografías**.
1. Se debe intentar que **el presentador** en el momento de la exposición **tenga el menor número de preocupaciones** ajenas a esta.
1. Cada vez que haya un **cambio de rumbo**, **explicar** claramente las **fuerzas que han llevado a cabo tomar esta decisión**.
1. Pocos **objetivos** pero claros y **en** estrecha **relación con el MVP**.
1. **Tener en cuenta de las horas totales que han planificado para el MVP** y cada vez que se alcancen hitos en horas (i.e: 100 horas de las 2400 horas totales) **se deben plasmar qué se ha usado el tiempo** para asegurar el tiempo útil.
1. Tener claro cómo se invierte  el tiempo. **Debe quedar plasmado en las presentaciones** cuánto y **en qué se va consumiendo el tiempo a cada hito/iteración/semanalmente** (**añadiendo captura de clockify**) o el que falta para el resto de semanas .
1. Conocer bien las capacidades financieras de los clientes.
1. Ser coherente con lo que expones en la presentación y con lo que explicas
1. **Dar énfasis a ciertos puntos críticos de la presentación** para **mantener la atención del público**, **cambiando la entonación** para que **no** sea demasiado **monótona**.
1. Los roles no son permanentes
1. **Tener en cuenta la existencia de bots** asegurando  seguridad y fiabilidad.
1. **Pedir feedback de empresas grandes** e incluso tener como usuarios pilotos  **si son parte del negocio**.
1. **Organizar el tiempo para cada apartado de la presentación.**
1. **Evitar permanecer demasiado tiempo en una diapositiva o dejar explicación sin soporte visual**, hace complicado seguir la presentación.
1. **Nunca ponerse a la defensiva cuando se proponen ideas o dudas por parte del público.** Empezar con frases como **“Primero gracias por tu feedback, …”.**
1. Empezar siempre con una **presentación de los ponentes y el número de grupo de forma alta y clara.**
1. Durante la presentación se debe **ser “cercano y formal”**, siempre cuidando los términos que se usan.
1. **Especificar a la hora de evaluar a la competencia**, en caso de que nuestra alternativa lo haga mejor, **QUÉ y CÓMO hace mejor que ellos**.
1. Siempre tener en cuenta el **coste y planificación de trabajos “secundarios”** (p.e: colocar QRs en máquinas)
1. **Exponer** siempre claramente **la organización y los integrantes del grupo**.
1. Tratar de **homogeneizar las fotos de los participantes**, que no tengan fondos muy diferentes.
1. Dejar claro que todos **los integrantes conocen la tecnología** con la que van a trabajar (si no, especificar tutorial/curso que se va a proporcionar)
1. **Tener claro** y exponer **el número de suscripciones mínimo para que sea rentable y estable en el tiempo**.
1. Procurar **eficiencia al dar información**; se tiene que decir poco y bueno.
1. **El acompañante debe estar completamente atento a lo que presenta el compañero** sino puede parecer que no tiene importancia lo que se expone.
1. **Hablar alto y claro**, proporcionar un micrófono si fuera necesario.
1. **En vez de situar** competidores **o elementos  en lista** (de ventajas y desventajas), **realizar un mapa y agruparlos por similaridad** para evaluarlos de esta manera.
1. **No confundir análisis de costes con el resto de conceptos** (i.e: TCO).
1. Es esencial tener **firmado el acuerdo de compromiso**.
1. En el commitment agreement, que no sea el propio afectado que ha hecho menos del 50% el que deba dejar el grupo.
1. La **política de gestión de prompts para las IAs** debe ser accesible y estar organizada.
1. Todos los miembros deben tocar algo de desarrollo.
1. Evitar demasiados clientes distintos.
1. Las diferencias con el resto de competidores deben quedar suficientemente claras.
1. **Tener en cuenta los costes de la plataforma** (p.e: operaciones), añadir planes sobre q**ué hacer en caso del aumento o disminución de usuarios**.
1. Se deben **identificar las responsabilidades de cada grupo de trabajo**. **Evaluar cómo evolucionan** **cada semana** las responsabilidades.
1. Explicar cuál ha sido el **proceso y criterio de búsqueda con los competidores**.
1. Relacionar entre sí la matriz DAFO (p.e: Amenazas vs Fortalezas) concretamente: 1ºA, 2ºF, 3º D, 4º O
1. Hay que hablar la base de conocimientos común.
1. En los costes **no poner los céntimos en la presentación**, no es necesario ese nivel de detalle, **en vez de 61.120,60€ poner 60k**.
1. NO HACER PREGUNTAS AL PÚBLICO.

## <a name="_35xmkliq9lbp"></a>**Consideraciones para IT TALENT**
Las **diferencias con el resto de competidores deben quedar suficientemente claras**. 

¿Qué pasa si el usuario tiene su perfil o repositorios privados? – Es el propio usuario, una vez envía su cv, acepta las políticas de usos de sus datos deberá también introducir su key si quiere que se use su información privada. ← Explicar en presentación.

Trataremos de tener acceso a todos los repositorios posibles en los que esa persona ha participado (teniendo en cuenta si el repositorio en el que ha participado no es suyo).

Para solucionar los problemas de privacidad cambiar el objetivo parcialmente: **Que busque un talento grupal**, un grupo de personas que se encarguen de una necesidad ofertada por una empresa (problema grande, real y actual), **que nuestra aplicación busque al grupo completo**. Sería una innovación que se busca mucho en empresas actualmente. **Subir la búsqueda desde las empresas 1-1 a 1-n**.

**Sacar información de Stackoverflow.**



## <a name="_gwy715co0tk5"></a>	**Tareas**
- Mejorar el “business statement”.
- Menos texto y más metáforas visuales.
- Tipo de negocio: ¿Cliente = usuario?, ¿matchmaking?
- Mejorar análisis de coste preliminar, mirar píldoras teóricas sobre ello.
- ¿Qué análisis se ha hecho para los competidores? Que estén como mínimo los primeros que aparecen al buscar en Google negocios similares.
- Usuarios pilotos potenciales reales. Tener una lista a parte de los alumnos del grupo de tarde.
- Definición del MVP con estudio de casos de uso core.
- Mockups iniciales -> interactivos y que te diferencien de la competencia.
- Discusión sobre la tecnología o innovación necesaria para desarrollar el proyecto
- Refinar temas de equipo como los roles.
- Más información sobre commitment agreement, en profundidad, darle otra vuelta.
- Report de uso de IA – Gestión de uso de prompts (que todo el mundo los tenga prompts para poder hacer cuestiones de un mismo tema en diferentes ordenadores)
- Análisis de riesgos preliminares. Se pondrá una píldora teórica sobre ello.


1. # <a name="_3n6nqs3ox56d"></a> Semana 2 (13/02)
## <a name="_4ki1iznv6aw6"></a>**Cosas a tener en cuenta**

1. Hay que **comenzar las presentaciones de manera clara** con un “Impacto” inicial. Importancia de los “Killer openers”. (Hay una píldora que lo trata)
1. Dar gran **protagonismo a los casos de uso core, la idea de negocio y los mockups**.
1. Si se **comparan competidores** o herramientas similares se debe hacer **hincapié en el elemento diferenciador.** 
1. **Si existen alternativas gratuitas** al comparar competidores se debe **justificar qué provocaría el cambio/paso a nuestra herramienta**.
1. Si es **un elemento el que nos diferencia de la competencia, el pricing debería ir enfocado a este.**
1. **Las promesas no deben ir al final**, si no **al inicio para usarlas como enganche para el público. Los mockups al final**
1. **Cuando se dicen riesgos** debe estar claramente identificado **de qué manera podría pasar y cómo se solucionaría con detalle.** (Por ejemplo, si uno es falta de conocimiento y se propone una formación, especificar la duración de la misma).
1. Al comentar **el commitment agreement**, se deben **exponer posibles problemas de equipo que ejemplifiquen**. (Por ejemplo, si alguién no tiene una tarea tiempo, ¿Qué va a pasar?)
1. Promover y **mostrar la evolución del commitment agreement** además de **medir cómo se cumple**.
   El **TCO debe estar expresado de manera mensual** no anual.
1. Al exponer **un riesgo es importante describirlo como un evento que puede ocurrir** y **describir** los **daños** o pérdidas **que causaría**.
1. Si se expone **un riesgo, se presenta la solución por delante**.
1. **Los análisis de costes** son más inteligibles **en forma de tabla**.
1. Los **costes de herramientas y/o licencias de pago** (por ejemplo github) deben ser tenidos en cuenta. **Si es un servicio gratuito** se debe **exponer la existencia de un plan si este deja de serlo**.
1. **Dejar claro que TODOS los integrantes han firmado el commitment agreement.**
1. **No sentarse en la mesa** para exponer.
1. Un fondo negro dificulta la lectura.
1. Uso de fuentes anchas y grandes.
1. Al proponer precios **debe quedar claro los beneficios que se están sacando** (TCO).
1. Siempre **tener en cuenta el feedback de semanas anteriores al exponer**. Marcar con una “F” las diapositivas que hacen referencia a este feedback.
1. **Se puede presentar un trabajo con carencias** con su debida justificación **pero** **las excusas no** son efectivas en la evaluación.
1. Tener un orden con **sentido y coherencia en la presentación** (No empezar exponiendo a los integrantes), **comenzar exponiendo el producto**.
1. Dejar los **mockups para el final.**
1. **Comenzar a exponer con confianza**. Uno debe creerse lo que está diciendo al presentar.
1. Es importante tener un **uso del tiempo** (clockify) justificado y **coherente**.
1. **Hacer pública la base de conocimientos del equipo**.
1. El **commitment agreement debe servir también como monitorización del riesgo**. Se debe **incluir en la presentación semanal y usarlo como autoevaluación.**
1. Añadir una **transparencia de autoevaluación**.
1. **Relacionar la tabla de riesgos y el commitment agreement**.
1. **No usar** la palabra **“castigos” en el commitment agreement** (mejor usar penalización). **Es más eficiente y se funciona mejor mediante recompensas o “Service credits”**.
1. Hacer **hincapié en una diapositiva** si hay **información relevante**.
1. Al **exponer** se debe buscar un **término medio entre energía y rapidez**.
1. Para **asegurar un uso de la aplicación en el tiempo** pensar en herramientas como la **gamificación**.
1. Para **empatizar y sensibilizar al público** dar alguna **experiencia personal** que enlace o sea **coherente con el proyecto**.
1. La **iconografía** debe ser **entendible** **o**, en su defecto se debe **apoyar de texto**.
1. **Desarrollar los costes de contingencia**.
1. **No confundir riesgos** que pueden darse o no **con hechos** (por ejemplo, falta de conocimientos), **causas** (por ejemplo, la falta de conocimientos acaba retrasando un milestone) **o debilidades**.
1. **Incluir matriz RACI.**
1. Priorizar la **originalidad**, usar ChatGPT sin pasarse.
1. Seguir un **discurso lógico** y una “historia” durante la exposición.
1. Cada vez se necesita **más eficiencia** a medida que se añade contenido.
1. **Mockups** más claros **que hagan uso de toda la pantalla**.
1. **Responder a lo que se espera** en ese día e ir cotejándolo.
1. **Commitment agreement** actualizado para **que refleje que todas las tareas tienen un miembro asignado y un responsable**. Debe poder usarse a la hora de cotejar que todo esté al día.
1. Asegurar el **cumplimiento del commitment agreement** semanalmente, poner ejemplos **con anécdotas anónimas**.
1. **Seguimiento del plan de riesgos** **y** un **informe del cumplimiento**.
1. Si te **pasas de horas** debe haber una **re-evaluación del alcance ó reducir las de otras semanas**.
1. **No poner precios por hora** para cada rol. Se debe **poner la hora básica de servicio** y realizar **multiplicadores** (por ejemplo, un jefe de proyecto suele cobrar un x2.5 sobre la básica).
1. Fotos homogéneas.

## <a name="_es35wsm2my6q"></a>**Consideraciones para IT TALENT**
Uso de **iconografías** sin descripción en la comparación con otras empresas.

Dejar claro que el **uso de RRSS para el registro es opcional**, nunca se pretende ser intrusivo en la vida personal del candidato, lo último que buscamos es perturbarlo con estos análisis.

Dar mayor **protagonismo a los mockups**, **casos de uso core** y la **idea de negocio**.

Hay que asumir los **costes de github y tenerlos en cuenta**. Si asumimos que es gratuita la licencia, ¿Qué pasaría si no? ¿Cuántas github action usaremos al mes?

Se debe dejar claro de **dónde sale el cálculo de precios** y cuál es el **beneficio** que se saca de estos. 


## <a name="_xw8pcxlaup9y"></a>**Tareas - ¿Qué no puede faltar?**

- Presentación de **16 minutos**.
- Hablar y **dejar clara la idea clave del negocio**.
- Hacer **inicio efectivo de la presentación**, contar en muy poco **de qué va el proyecto** para que inviertan en él y tratar de realizar el “elevator pitch”.
- Hablar del **tipo de negocio**.
- Dejar clara la **diferencia entre usuario y cliente, ¿Quién paga?**
- **Re-evaluar el análisis de competidores** con el nuevo feedback.
- **Re-evaluar el análisis de costes**; indirectos, oficinas, herramientas, licencias…
- **Gestión de usuarios pilotos** (píldora teórica).
- **Mockups, casos de uso core e idea de negocio claros**.
- Discusión sobre la **innovación que pudiera ser necesaria** y stack tecnológico.
- **Elaborar análisis de riesgos** (píldora teórica).
- Fotos homogéneas.
- Tratar el **commitment agreement** con el feedback que se ha dado.
- **Evaluar la manera en la que se ha hecho uso de IAs**.
- **Comenzar a hablar algo del desarrollo** e ir comenzando, por ejemplo:
  - **Aseguramiento de la Calidad**
  - Posibilidades de mejora
  - Cómo **medir el rendimiento** de cada miembro durante el desarrollo
  - **Herramientas** obligatorias **para el desarrollo**;  github,:project, actions…, 
  - **Herramientas de análisis de código**…
  - Evaluar el **control del tiempo usado y por usar.**
  - Evaluar y **planear la gestión del código**.
  - Evaluar y **planear los despliegues múltiples**.
  - Planificar **qué se va a hacer en el sprint 1 y grosso modo los siguientes sprints**.
- Elaborar **una página donde se hable del proyecto. Que** haya enlaces y formas de **contacto** con responsables.

1. # <a name="_chp71xun2gc6"></a> Semana 3 (20/02) 
## <a name="_jnimpmeuvwuu"></a>**Cosas a tener en cuenta**

1. Si se realiza un **Killer Opener**, este debe ser corto **sin demorarlo demasiado** sino deja de ser efectivo.
1. Situar la **marca de feedback en la parte superior** de la presentación.
1. Al presentar los **mockups** debe ser **en** **pantalla completa y** realizando **zoom** cuando se haga referencia a partes concretas que no sean legibles al fondo de la clase.
1. Es importante **“afilar” los argumentos**, **sintetizar** de manera **que quede solo lo esencial.**
1. Al comparar con los competidores **hacer énfasis en los puntos que mejora nuestra aplicación**.
1. Dejar claro el **estado de la comunicación con los usuarios pilotos**.
1. Dejar claro el **versionado** que se usará en la gestión del código.
1. Tener una **gestión de la documentación** similar a la del código con github. Por ejemplo, la **presentación** debería subirse **como una pull request** con todo el grupo como revisor.
1. Tener un **workflow** para la gestión **de la documentación**.
1. Se debe dejar claro que la **presentación** ha sido **revisada y escuchada por todos los miembros** del equipo y que estos han aportado su feedback.
1. Si se han aplicado **medidas** para solucionar un problema hay que **plasmar, evaluar y medir** cómo de buenas han sido estas.
1. Tener claros y **plasmar las metas y objetivos del sprint sobre el que se trabaja y los siguientes.**.
1. **No quejarse** NUNCA en medio de la presentación.
1. Plasmar la refactorización de equipos en la presentación.
1. ` `Los costes deben aparecer junto al TCO destacando claramente este último.
1. A la hora de enseñar datos económicos, separar claramente los costes de los beneficios.
1. **Evitar exponer un riesgo que implique** el **fracaso** de la aplicación en la presentación.
1. Estructurar la información de manera que sea entendible y visualmente atractiva.
1. Valorar y revisar que cosas son mejor realizar con github pages o con docusaurus.
1. Presentar la **“landing page” con un QR visible** para llamar la atención de los espectadores.
1. **Cuando un profesor da feedback** sobre algo se debe **aceptar y escuchar el comentario completo** y más tarde clarificar si este estaba en un error.
1. Evaluar si un índice es realmente necesario en la presentación.
1. Ser eficientes con la información retratada en las diapositivas. (por ejemplo, **evitar tablas en las comparaciones**)
1. Evitar uso de colores en las tablas.
1. **Evitar fuentes** más **finas** sobre fondo blanco.
1. Mencionar siempre **dónde trabajan** todos **los miembros** del equipo.
1. Dejar claro y **desglosar los costes de** las **licencias** pertinentes.
1. Presentar datos y **estadísticas de pull request e issues**.
1. Presentar datos **como de efectivo** está siendo el **uso de las IA y prompts**.
1. Buscar **usuarios piloto** que puedan elegir los **roles que se ajustan a su perfil**.
1. Si hay diferentes **categorías de suscripción**, **decir**las **incrementalmente** marcando con negrita **las mejoras** de una con respecto a la siguiente.
1. Uso de imágenes realistas y profesionales de ejemplo en los mockups.
1. **Mirar a** todo el **público** al exponer.
1. Realizar **plan de monitorización del feedback** de usuarios piloto.
1. Moverse y no estar de brazos cruzados cuando se expone.
1. **No incluir datos teóricos** o del temario en la presentación.
1. **No** usar **polémicas** como Killer Opener.
1. **Cotejar la autoevaluación con** el grado de cumplimiento de cláusulas del **commitment agreement**.
1. Expresar con **gráficos y medir** adecuadamente **el grado de rendimiento de los miembros** del grupo.
1. Tener clara y exponer la **gestión de usuarios piloto**.
1. Si hay **recompensas** para los usuarios piloto, debe estar **recogido en el TCO**.
1. **No** usar **fondos degradados**, es complicado controlar un formato o fuente legible.
## <a name="_o9sh85hrxn04"></a>**Consideraciones para IT TALENT**
- **Acortar el Killer Opener.**
- Tenemos **demasiadas horas** para las tres semanas de trabajo usadas.
- **Mover la marca de feedback** en la parte superior.
- Hacer **zoom** en los **mockups**.
- No decir “BOFF ANDA QUE NO CANSA NÁ”. 
- Es importante “afilar” los argumentos, quitar la paja y dejar lo esencial.
- **Quitar** la palabra **“plan”** del pricing.
- Los competidores tienen una disonancia visual, **destacar en los 3 puntos que vamos a trabajar como mejora del resto**.
- Dejar claro el **estado de la comunicación** con los usuarios pilotos.
- Dejar clara la **gestión del código**, el versionado de la aplicación…
- Tener una **gestión de la documentación** similar a la del código con github. Por ejemplo, la presentación debería subirse como una pull request con todo el grupo como revisor.
- Se debe dejar claro que **la presentación** ha sido **revisada y escuchada por todos los miembros del equipo** y que estos han aportado su feedback.
- Cambiar nombre a **IT**alent.
- Uso “**Opening**” con 2  n’s en la presentación.
- **Medir cómo de buenas son las medidas** que decidamos usar **para reducir tiempo** de reuniones.
- Reflejar las **metas por sprint** en la presentación.
- Hablar sobre la **retrospectiva semanal de forms en la presentación**.
- Revisar arquitecturas de microservicios para ver si tienen cabida en nuestro proyecto.
## <a name="_hp9ikto9rfsy"></a>**Tareas - ¿Qué no puede faltar?**

- Enseñar **capturas de github**; número de contributors, calculadora con los precios, actions...
- Plasmar **todas las cláusulas** del commitment agreement de manera breve y marcar cada una como **verde/rojo** si se ha cumplido o no.
- Plantear la **documentación como código**. Describir poco y bien.
- Transparencia en la que queden claro los **usuarios piloto y potenciales** y **el estado de las comunicaciones** (contactado/pendiente de respuesta) con ellos.
- Dejar claro **si la presentación ha sido ensayada** con todo el grupo y recibido feedbacks de estos en la presentación.
- Transparencia de **autodefensa** ¿**Cuánto cubre** la presentación **del total pedido** para esa semana?
- Probar a grabar la presentación, conseguir **transcripción** y pedir **a ChatGPT** como hacerla en menos tiempo o más sintetizada.
- Presentación de **15 minutos**.
- Informar a los usuarios pilotos de **cuándo** vamos a tener una **aplicación usable**, para **cuando necesitamos** que la prueben y **qué vamos a requerir** de ellos. 
- Se proporcionará información sobre que debe estar reflejado en **la presentación** del **feedback de los usuarios pilotos** a parte de información adicional que creamos pertinente.
- Ahora que se va a presentar desarrollo, la **presentación** debe ser **más técnica**, pero debe **seguir quedando claro en ella el modelo de negocio**.
- En torno a un **15/20%** se debe desarrollar el **modelo de negocio**:
  - Seguir elaborando **Killer Opener**.
  - Seguir trabajando un **Elevator pitch**.
  - Resumen de **análisis de competidores** y que nos diferencia.
  - Resumen de **análisis de costes**.
  - Resumen de **estructura del equipo** en base a roles, jerarquía…
  - Estado de **cumplimiento del commitment con métricas**.
- Otro **15%** el **prototipo** con lo desarrollado en la **primera semana** **del sprint 1:**
  - Todo lo **visual**.
  - El **backend**: Lo que se pueda mostrar de manera pertinente (ver como poner algoritmos/código)
- **40/45%** **la retrospectiva** de esa primera semana:
  - **Metodología** empleada.
  - **Análisis de la calidad.**
  - Transparencia con el **rendimiento de miembros** (anónimo) **comparado**: **en** **función del rol** de cada uno.
  - Exponer **problemas que se han dado** y eran riesgos (p.e: reuniones muy largas, efectividad programando…) **con las medidas tomadas para su solución**: medirlas y cuantificarlas, ¿Ha sido suficiente? ¿Debe ser mejorada la medida? 
  - También decir sí hemos encontrado **problemas que no eran riesgos**.
  - **Lecciones aprendidas.**
  - **Reloj de avance del proyecto** (clockify): horas invertidas, diferenciar horas de clase y de trabajo en casa… E incluir links donde se ve lo que se va trabajando con las horas que ha dedicado cada uno.
- Otro 15% la **planificación o re-planificación** que se haya podido dar: (interesante dejar el sprint 3 más vacío como contingencia)
  - Hablar de los **objetivos del sprint 2** y como afecta a la planificación global.
- 10% la **gestión de usuarios piloto**.
- R**eport de gestión de IAs** toma mayor importancia (copilot): **cómo han ayudado** o **cómo NO han sido útiles, todo**.
##
1. # <a name="_pqh61qryn031"></a><a name="_at55to1wrtcp"></a> Semana 4 (27/02)
## <a name="_1n0ltkyakv2"></a>**Cosas a tener en cuenta**

1. Resumen de **análisis de competidores siempre** debe estar **presente** en las presentaciones.
1. Siempre debe haber una **transparencia** con la **productividad por miembro** del equipo (horas).
1. Mantener siempre una **diapositiva con la Landing Page** con **QR** aunque sea en la última diapositiva.
1. A cada sprint siempre se debe **mostrar la planificación** o **re-planificación** **de** los **próximos sprints**.
1. En caso de tener problema **valorar** la posibilidad de **mover tareas** de un **sprint** a otro.
1. Se busca una mejora de la síntesis cada semana, **no** se deben **eliminar conceptos** de una a otra.
1. El **rendimiento** se debe medir **individual**mente y no en grupo.
1. En la **autoevaluación** debe haber un **análisis** con **métricas** y números claros.
1. Siempre que se muestren **problemas en el trabajo** en equipo, se deben **presentar** **medidas** que se tomarán para solventarlos **con** las **métricas** con las que se medirá la eficacia de las respuestas.
1. El **análisis de competidores** debe estar **más sintetizado**, parándose en los 3 más similares a nuestra plataforma, focalizando en la característica más “killer”.
1. El **elevator pitch** debe estar siempre claramente **presente**.
1. **No confundir coste de mantenimiento con** coste de **operación**, el mantenimiento puede ser por ejemplo el correctivo (para posibles fallos) o aumentativo (hay suficiente dinero como para hacer añadidos).
1. Cuidar y **evitar las muletillas**.
1. Siempre cuidar y **tener claro el hilo de la presentación**. Debe de haber coherencia entre los puntos y **no dejar conceptos sueltos**.
1. Se debe dejar claro la **planificación de** cada **sprint**, sobre todo si ha habido problemas de rendimiento en una semana, ¿**Cómo afectan** estas carencias **a** los **próximos sprints**?
1. ` `No basta con mostrar los problemas que ha habido durante la semana de trabajo, se debe **mostrar siempre el análisis de riesgos inicial.**
1. Durante el **desarrollo** dar **preferencia a las funcionalidades core** o del MVP, por ejemplo, si el login es secundario no debería estar siendo desarrollado en el primer sprint cuando el objetivo es acabar el MVP.
1. Cuanto mayores son los números en cuanto a **ROI** mayor debe ser el Elevator Pitch, orientado a estos números. Si son poco realistas deben ser **repensados**.
1. Debe quedar reflejado en la presentación que cuando **no se llega el trabajo** planificado **se ha incumplido alguna cláusula** del Commitment Agreement.
1. El **rendimiento** no es la inversión del tiempo si no el **uso efectivo** del mismo.
1. En el Commitment Agreement se debe plasmar si se ha **logrado los objetivos**, sin tener que ver con el número de horas, si no con **el rendimiento** de estas y si han **aportado al desarrollo final**.
1. No olvidar que es el **moderador** quien **lleva el conteo del tiempo** (fuera de evaluación) de las presentaciones.
1. Siempre incluir los **estados de la comunicación** y gestión de usuarios pilotos.
1. Hablar de **porcentajes del número de usuarios que tienen que usar nuestra aplicación** (TCO) con respecto al número de usuarios potenciales. 
1. Si no se llega al 100% del trabajo que se pedía, se debe **justificar** con un motivo de peso o **penalizaciones** sobre el Commitment Agreement o la **evaluación grupal** de la persona implicada.
1. Reflejar en el Commitment Agreement cuando personas tiene penalizaciones o **“ya no van a por el 10”**
1. Si se dicen las **tareas** que ha hecho cada subgrupo deben ir acompañadas de un **diagrama de gantt simplificado** o similar en el que se vean para cuando estaba planificada cada una.
1. **No mezclar** la **retrospectiva** con la **autoevaluación**.
1. Si hay una **propuesta de mejora** se debe decir **cómo se va a medir** de antemano, antes de tomar la medida.
1. Indicar con triángulos hacia arriba o abajo cuando haya habido **rendimiento positivo o negativo** en la retrospectiva.
1. Pensar en si es mejor una **DEMO grabada** o en directo.
1. El **testing** no puede estar presente solamente en el sprint 3, deben ser **FAST**, se deben hacer a lo largo de todos los sprints.
1. El **TCO** debe ser **mensua**l, no global (anual).
1. Deben quedar claro los **responsables de una tarea**.
1. **No suspirar** a lo largo de la presentación, da sensación de agotamiento de lo que se está contando.
1. Aclarar y **enlazar el Killer Opener** con el inicio y el resto de la presentación.
1. Falta claridad en el **TCO**. Se necesita **definir** un **marco de tiempo** (time frame) y una **capacidad de demanda nominal** para comprender mejor cómo se comportará el sistema en diferentes condiciones de uso, en resumen, **cómo escalará**. No solo se trata de **cuántos usuarios pueden usarlo al mismo tiempo**, sino también de **cuándo y** con qué **nivel de demanda**.
1. En la presentación deben quedar claros los **análisis del rendimiento**  y los límites operativos **de github** (github actions) para **justificar el plan** que necesitamos. Por ejemplo, cuánto tarda en evaluar a X usuarios para formar un grupo.
1. Las **métricas del rendimiento** debe ser capaz de comparar cada miembro del equipo y los datos obtenidos deben ser cotejados para evaluar al final de cada sprint. Para los que programan es sencillo; nº de commits… Pero ¿Cómo se está midiendo el rendimiento de la persona que coordina?
1. El **DAFO** ya **no** merece la pena **incluirlo** en la presentación.
1. El **número de usuarios** que necesitamos para mantener la aplicación debe tener **porcentajes** con respecto al número de **personas en el sector** en Sevilla por ejemplo.
1. **No** meter una imagen de un **QR si no es funcional** o al menos aclarar que no lo es.
1. **Usar recursos** en la presentación como **líneas o subrayados** para corresponder con lo que se dice.
1. Recordar que **como presentador** no recae en uno las responsabilidades del grupo al completo, **disfrutar de la presentación.**
1. Evitar sobrecarga en las **presentaciones**, buscar la **simplicidad** y la **correlación** entre diapositivas. 
1. Se debe ser **coherente** lo que se refleja en la diapositiva con lo que pone en el **título**. 
1. Aunque se realice un Killer Opener, los presentadores deben decir sus nombres. 
1. Marcar más el **reconocimiento** que se dice que se tiene sobre el Commitment Agreement. Poner un **pódium** con los nombres. 
1. Evitar **letras blancas** sobre **colores claros**. 
1. Las **DEMOS** de los prototipos se deben ver bien, hacer **zoom**.  
1. Si hay **datos en el tiempo** (días) poner como apoyo visual un **calendario**.

## <a name="_k9wifui2ze97"></a>**Consideraciones para IT TALENT**
- No suspirar a lo largo de la presentación, da sensación de agotamiento de lo que se está contando.
- Aclarar y **enlazar el Killer Opener** con el inicio y el resto de la presentación.
- Falta claridad en el **TCO**. Se necesita **definir** un **marco de tiempo** (time frame) y una **capacidad de demanda nominal** para comprender mejor cómo se comportará el sistema en diferentes condiciones de uso, en resumen, **cómo escalará**. No solo se trata de **cuántos usuarios pueden usarlo al mismo tiempo**, sino también de **cuándo y** con qué **nivel de demanda**.
- Hablar en profundidad de nuestra **gestión de la documentación**, mostrar el versionado de documentos que se lleva internamente.
- En la presentación deben quedar claros los **análisis del rendimiento**  y los límites operativos **de github** (github actions) para **justificar el plan** que necesitamos. Por ejemplo, cuánto tarda en evaluar a X usuarios para formar un grupo.
- La tabla de TEAM PERFORMANCE está bien, no cambiarla demasiado, pero le ha faltado la performance individual.
- Faltan **gráficas** y **métricas del rendimiento** por cada integrante del equipo (anónimo). 
- Las **métricas del rendimiento** debe ser capaz de comparar cada miembro del equipo y los datos obtenidos deben ser cotejados para evaluar al final de cada sprint. Para los que programan es sencillo; nº de commits… Pero ¿Cómo se está midiendo el rendimiento de la persona que coordina?
- El DAFO ya no merece la pena incluirlo en la presentación.
- Diferencias entre **gitflow** y **goldenflow** y decir cual nos merece la pena usar.
- El **número de usuarios** que necesitamos para mantener la aplicación debe tener **porcentajes** con respecto al número de **personas en el sector** en Sevilla por ejemplo.
- Pensar en si es mejor una **DEMO grabada** o en directo.
- Marcar más el reconocimiento que se dice que se tiene sobre el CA. Poner un **pódium con los nombres.**
## <a name="_816kw56t22l9"></a>
## <a name="_w1wwzt1pmvgj"></a>**Tareas - ¿Qué no puede faltar?**
- Falta claridad en el **TCO**. Se necesita **definir** un **marco de tiempo** (time frame) y una **capacidad de demanda nominal** para comprender mejor cómo se comportará el sistema en diferentes condiciones de uso, en resumen, **cómo escalará**. No solo se trata de **cuántos usuarios pueden usarlo al mismo tiempo**, sino también de **cuándo y** con qué **nivel de demanda**.

estaría bien decir el

sistema de memoria planteado para minimizar el número de llamadas
- En la presentación deben quedar claros los **análisis del rendimiento**  y los límites operativos **de github** (github actions) para **justificar el plan** que necesitamos. Por ejemplo, cuánto tarda en evaluar a X usuarios para formar un grupo.
- La tabla de TEAM PERFORMANCE está bien, no cambiarla demasiado, pero le ha faltado la performance individual.
- Faltan **gráficas** y **métricas del rendimiento** por cada integrante del equipo (anónimo). 
- Las **métricas del rendimiento** debe ser capaz de comparar cada miembro del equipo y los datos obtenidos deben ser cotejados para evaluar al final de cada sprint. Para los que programan es sencillo; nº de commits… Pero **¿Cómo se está midiendo el rendimiento de la persona que coordina?**
- Diferencias entre **gitflow** y **goldenflow** y decir cual nos merece la pena usar.
- El **número de usuarios** que necesitamos para mantener la aplicación debe tener **porcentajes** con respecto al número de **personas en el sector** en Sevilla por ejemplo.
- Pensar en si es mejor una **DEMO grabada** o en directo.
- Una vez que calculas el **coste al mes por X usuarios** se debe analizar **cómo cambia el coste necesario si se duplican, triplican, bajan**… el número de usuarios. Plantearlo para finiquitar el TCO para el resto de sprints.
- Si algún miembro ya no aspira al 10 con respecto al CA se debe indicar en la presentación.
- Poner los **responsables de las tareas** en la presentación y confirmar que está reflejado en el CA.
- El orden de la presentación debe ser similar entre grupos, concretamente:
1. **15% INTRODUCCIÓN** proyecto:
   1. Killer Opener
   1. Elevator Pitch
   1. Resumen Análisis de competidores
   1. Resumen de TCO:
      1. **Capex:** coste desarrollo,  licencias, personal de la empresa, portátil, amortización por varios projects…
      1. **Opex:** gastos hosting e infraestructura, customs, mantenimiento, ventas-marketing-anuncios, maquinaVM en la nube, mejoras, support, ventas para el cliente, copilot
      1. PORCENTAJE DE CAPEX VS OPEX EN GRANDE.
   1. Situación actual del presupuesto gastado vs TOTAL esperado.
   1. Estimaciones corto (4 /6 meses) y largo (12/24 meses) plazo de ingresos y medir el número de usuarios e ingresos divididas en **pesimistas**, **optimistas** y **realistas**.
   1. Refinar los roles de equipo, composición y jerarquía.
   1. Estado de cumplimiento del CA.
1. **15% DEMO FINAL** del sprint 1 con casos de uso core terminados.
1. **40 % RETROSPECTIVA** del sprint 1:
   1. **Rendimiento** del equipo (**mejora**/**empeora**, fórmulas) . POR MIEMBRO.
   1. Codacy, Sonar, algo de la **Gestión de la** **Calidad** del código.
   1. **Gestión de riesgos**.
   1. **Control** del rendimiento **de las medidas tomadas**. Si se ha encontrado un nuevo problema, proponer la solución y decir cómo se medirá el rendimiento cuando se emplee en el próximo sprint.
   1. **Lecciones aprendidas**.
   1. **Reloj de avance** del proyecto / **Clockify.**
1. **USUARIOS PILOTO**:
   1. **Gestión de usuarios**; feedback… a nivel mensual.
   1. Cuando vamos a entregar el MVP y cuando necesitamos el feedback + planificar el segundo sprint en este asunto
1. **PLANIFICACIÓN**:
   1. De esta semana y el **sprint 2**. ¿Hará falta re-planificación?
   1. Planificación del 3. ¿Hará falta **re-planificación?**
1. **REPORT DE USO DE IA**
1. Última diapositiva: **QR Landingpage.** Con nuestros **datos de contacto**.


# <a name="_bwryho14b15v"></a> Semana 5 (5/03)
## <a name="_7pmvecn522oa"></a>**Cosas a tener en cuenta**

1. **Evitar capturas de documentos**, no son legibles al fondo de la clase.
1. Tener **demos grabadas**, sobre todo para las jornadas de evaluación.
1. Las **estimaciones** a futuro **NO** pueden ser **lineales**, datos como el número de usuarios deben hacer **fluctuar** los datos.
1. Evitar colores claros sobre blanco en los **gráficos** y poner **etiquetas** en cada **eje**.
1. Poner la **estimación de gastos** e ingresos **con una gráfica**, evitar tablas con muchos datos numéricos o simplificarlas (pesimista, optimista...)
1. La estructura del equipo, jerarquía… Debe estar siempre presente.
1. No mezclar conceptos como el grado de cumplimiento y el análisis de rendimiento.
1. Decir los **milestones** en la presentación** para próximas semanas/sprints.
1. Evitar diapositivas con mucho texto y usar **iconografías**.
1. Añadir **gráfico** con los gajos **de horas individuales** de clockify. 
1. Para en la demo empezar por lo más importante, no el login.
1. **Evitar** hacer uso innecesario de **plataformas de comunicación** ajenas a GitHub, cambiarlo por el uso de **comentarios de github** o portales.
1. No poner títulos en inglés y español en las diapositivas
1. No confundir “Coste Total” con TCO.
1. Hacer usos de herramientas que proporcionan aplicaciones como **clockify** para los **gráficos**, **no realizar esfuerzo extra**.
1. Un **problema** no es hacer uso de más horas para una tarea, sino **mala asignación** de tareas.
1. Respetar el orden que se dijo en las clases para la presentación.
1. **Estimaciones de usuarios** (optimistas, pesimistas, realistas) con análisis **PERT**. 
1. **No** poner el rellenado de los **registros** en la **DEMO** de la aplicación
1. Realizar un **pseudo gantt** en la **retrospectiva** del sprint con las **tareas** que se han realizado en este.
1. La matriz **RACI no** se debe mostrar, **desarrollar** su contenido cuando se habla de **la gestión del código** en GitHub.
1. El uso de las **github actions** debe estar **desarrollado**, en qué se están usando.
1. Cada integrante debe saber la **justificación** de su **nota** en el sprint. Sobre todo si la nota es baja; se debe **hablar con el integrante** lo haya pedido este o no.
1. Desarrollar en la presentación cuál es el “**rational**” de las diferencias en el **cálculo del rendimiento** de coordinadores e integrantes.


## <a name="_3sdy5a40t2ft"></a>**Consideraciones para IT TALENT**
- **Eliminar** la captura del **formulario**, no es legible.
- Falta un **Elevator pitch claro**.
- Cambiar MPV por MVP.
- Tener una **demo grabada**.
- Para en la **demo empezar** por lo más importante, **no el login**.
- **Demasiados datos en el TCO**, hacen **complejo** entender y seguir la presentación.
- Las **estimaciones** a futuro (BUDGET) **NO** pueden ser **lineales**, datos como el número de usuarios deben hacer **fluctuar** los datos.
- Evitar colores claros sobre blanco en los gráficos y **poner etiquetas** en cada eje.
- Hacer poner  la clave de github (API) al cliente es arriesgado si la empresa es la que tiene que hacer los análisis. Sobre todo si el cliente ya usa su api para otras cosas, el **requisito de uso es demasiado alto**, no es profesional.
- Estimar el número de **peticiones** que se deberían hacer en **total** y decir cuánto nos costaría con la responsabilidad de **usar la API nosotros**.
- Deberíamos haber hecho el **análisis de la capacidad** de peticiones, para estimar el nº de peticiones óptimo para los clientes en los diferentes planes de subscripción.
- Tendríamos que hacer el **análisis económico** de las peticiones que harán los clientes.
- **Estimaciones de usuarios** (optimistas, pesimistas, realistas) más **simple**, realizar análisis **PERT**.
- Realizar un **pseudo gantt** en la **retrospectiva** del sprint con las **tareas** que se han realizado en este.
- Incluir **documentación** en el **repositorio** o en un docusaurus.
- Añadir los contributing.md al repositorio.
- Tiempo de visualización de los videos de las píldoras en el clockify.

## <a name="_v4g5emymkh6c"></a>**Tareas - ¿Qué no puede faltar?**
- Toda la **documentación** en una carpeta docs en el **repositorio** de github o en un docusaurus, usar **IAs para pasar a Markdown** o para hacer uso de la documentación de manera más ágil (poner comentarios…)**.** Pensar si hacer un **despliegue** de esta en app engine. Incluir la **documentación de los entregables** en el docusaurio.
- Hacer uso de  **conventional commits** con **metainformación** en los mensajes (tipo, milestones…).
- Para la semana que viene Presentación de retrospectiva de unos 15 minutos con:
1. Tablas con horas.
1. Tareas que hemos hecho.
1. Rendimiento del equipo.
1. Mecánicas de trabajo.
1. Commitment agreement, ¿Se cumple? ¿Modificaciones?
1. …
- Para dentro de 2 semanas:
1. **INTRODUCCIÓN**:
   1. Killer opener
   1. Elevator pitch
   1. Análisis de competidores
1. **Storyboard** (píldora teórica) de un anuncio para uno de los clientes. (Representantes o Candidatos)
1. **Impacto Legal** del proyecto – Incluir **Customer Agreement**. (Licencias, aspectos legales que nos afectan…)
1. **COSTES**:
   1. TCO
   1. Capex vs Opex
   1. Costes GActions
   1. Cuanto llevamos gastado con respecto al Total
   1. Estimaciones pesimistas, optimistas… Con respecto al número de usuarios
1. Refinar **estructura de equipo**
1. **DEMO** dinámica** sprint 2 - **Resaltar** que estaba en el S1 y que hemos hecho **nuevo**
1. **RETROSPECTIVA**:
   1. Rendimiento del equipo, desarrollando las fórmulas
   1. ALM: Automatización del código (ALM pill)
   1. Evolución de la calidad del código, Sonar, Codacy… ver incremento y decremento de métricas.
   1. Gestión de riesgos, riesgos que se han dado, problemas que no eran riesgos: Medidas, métricas, planes…
   1. Lecciones Aprendidas
   1. Reloj de avance de proyecto, clockify semanal y global
1. Gestión de **Usuarios Piloto**. – **Gestión del feedback** (demostrar que el usuario ha sido escuchado)
1. Re-estimación del **sprint 2** (tema documentos si quitan tiempo) y global del 3:
   1. Objetivos del 2: Incluir algo de Pagos / pasarelas de pago
   1. ¿Qué queda para el 3er sprint?
1. **Uso de IA**
1. QR **landing page**

# <a name="_3n6nqs3ox56d2"></a> Semana 7 (19/03)
## <a name="_4ki1iznv6aw62"></a>**Cosas a tener en cuenta**

1. Validar los correos electrónicos mediante alguna API y añadir los costes de esta al Opex.
1. Storyboards en blanco y negro poniendo en color lo que queramos destacar.
1. Si se trabaja en horario no lectivo con otros grupos debe ser por previo acuerdo entre ambas partes.
1. No confundir los acuerdos con los usuarios pilotos con el Customer Agreement, no son lo mismo.
1. A partir de ahora siempre deben aparecer los términos legales y políticas de usuario.
1. En las demostraciones no pueden aparecer nombres de ejemplo como “Usuario1” o “admin”.
1. Si se recorta el alcance se debe justificar, no solo por un “paso de horas” sino por qué se ha dado.
1. No usar líneas rojas en tablas en la presentación.
1. Se deben buscar siempre representaciones gráficas para los costes, evitar el uso de tablas en la medida de lo posible.
1. Los costes de las GActions no pueden faltar nunca en la presentación pero el desglose puede no estar presente.
1. Se debe saber desarrollar/justificar todas las columnas que aparecen en la tabla del análisis de competidores.
1. En la universidad se imparten “Lectures” no “Lessons”.
1. Realizar el desarrollo a partir de mocks para que el frontend pueda trabajar independientemente del backend.
1. Si es una demo auto explicativa se debe introducir adecuadamente para poner atención desde un principio.
1. En el storyboard se debe centrar en lo que diferencia del resto de la competencia.
1. En la presentación debe aparecer una gráfica de puntos de historia vs tiempo consumido.
1. Para medir la eficiencia de los tests, contar en base a los fallos que saltan con estos. También es buena practica poner los fallos a posta para que estos salten.
1. No confundir los términos Contrato y Acuerdo, los contratos tienen términos y componentes legales.


## <a name="_es35wsm2my6q2"></a>**Consideraciones para IT TALENT**
- Evitar uso de fuentes oscuras sobre fondos oscuros.
- En la DEMO hay letras muy pequeñas, por lo que es necesario hacer uso de zoom en el video.
- Pensar en usar colores más claros para la DEMO únicamente, manteniendo los colores en la aplicación original.
- Storyboards en blanco y negro poniendo en color lo que queramos destacar.
- Los presupuestos expuestos están demasiado centrados en el desarrollo.
- La grafica del Budget sobra con la otra grafica de costes y beneficios.
- Revisitar el tema de las métricas que se está usando para medir el rendimiento. Separar el número de horas en el rendimiento, no confundir con el esfuerzo.
- Revisar los usuarios pilotos que no responden y acotar los que sean menos probables.
- El elevator pitch debe estar más presente. No solamente como una frase introductoria. (como musclemate, qué ofrecemos nosotros que otros no)
- En el storyboard del empresario buscar destacar la característica que nos diferencia (le hagan falta 5 personas para YA con unas especificaciones CONCRETAS).
- Dar coherencia a la presentación de manera que si mostramos a unos actores en el storyboard, usarlo como recurso a lo largo de la presentación, en por ejemplo en la demo…
- Validar los correos electrónicos mediante alguna API y añadir los costes de esta al Opex (No estoy seguro de que correos se refería, si a los de las empresas o a los usuarios de la aplicación en general).
- Hacer gráfica de puntos de historia vs tiempo consumido.
- Para medir la eficiencia de los tests, contar en base a los fallos que saltan con estos. También es buena practica poner los fallos a posta para que estos salten.
- Capex, costes de desarrollo, mostrar multiplicador por cada rol (sobre la hora de servicio mínima) (Para este parto sobre los comentarios de Müller de Ocial, destacó especialmente esta diapositiva).


## <a name="_xw8pcxlaup9y2"></a>**Tareas - ¿Qué no puede faltar?**


- Hablar del commitment agreement de los usuarios pilotos.
- Justificar recortes de alcance.
- Es obligatorio meter en las issues a los encargados de revisión.
- Hacer números sobre el uso de la IA, si se esta usando: ¿Cuánto tiempo nos está ahorrando? (número de horas), si se dan errores en las consultas ¿Cuántos refinamientos han hecho falta?, ¿El uso repetido te esta formando para ingeniería prompt?...
- Las mejoras y adiciones sobre el sprint anterior deben estar claras. 
   - Hacer análisis de los conventional commits para evaluar las mejoras: contar número de fixs…
- De deben ver ya las pasarelas de pago y que aparezcan los acuerdos.
- La evolución del opex debe ser no lineal
- Tener y mostrar un calendario compartido para ver las horas libres para las reuniones.

1. **INTRODUCCIÓN**:
   1. Killer opener
   1. Elevator pitch, con un par de frases predefinidas. Recordar que se busca convencer a los inversores.
   1. Análisis de competidores, centrarnos en las features killer y pasar poco por el resto.
1. **Storyboards**
1. **Impacto Legal** del proyecto – **Customer agreement**, GDPR, licencias, aspectos legales...
1. **COSTES**:
   1. TCO
   1. Capex vs Opex
   1. Costes GActions
   1. Cuanto llevamos gastado con respecto al Total
   1. Estimaciones pesimistas, optimistas… Con respecto al número de usuarios
1. Refinar **estructura de equipo**
   1. Estado del Commitment Agreement
1. **DEMO** dinámica** sprint 2 - **Resaltar** que estaba en el S1 y que hemos hecho **nuevo** con el resto feedback; casos de uso corse, historias de usuario, imágenes reales…
1. **RETROSPECTIVA**:
   1. Rendimiento del equipo, desarrollando las fórmulas
   1. ALM (ALM pill)
   1. Evolución de la calidad del código, Sonar, Codacy… ver incremento y decremento de métricas.
   1. Gestión de riesgos, riesgos que se han dado, problemas que no eran riesgos: Medidas, métricas, planes…
   1. Lecciones Aprendidas
   1. Reloj de avance de proyecto, clockify semanal y global
1. Gestión de **Usuarios Piloto**.
   1. **Gestión del feedback** (demostrar que el usuario está siendo escuchado)
   1. Resumen del feedback proporcionado
   1. Acciones de consolidación que se han tomado a partir de ese feedback
   1. Planes con los usuarios piloto para el S3
   1. Commitment Agreement con los usuarios piotos
1. Re-estimación del **sprint 3**:
   1. Justificar si hemos tenido que reducir el alcance
   1. Objetivos del 2: Sandbox de pago / pasarelas de pago
   1. ¿Qué queda para el 3er sprint?
1. **Uso de IA**
1. QR **landing page**


# <a name="_3n6nqs3ox56d22"></a> Semana 8 (02/04)
## <a name="_4ki1iznv6aw622"></a>**Cosas a tener en cuenta**

1. En diapositivas que contenga gráficas se debe parar un mínimo para explicarlas.
1. Uso de datos y descripciones realistas en las demos.
1. Cuidar formatos en las diapositivas que hagan las letras más pequeñas, pueden hacerlas ilegibles.
1. Siempre hacer algún comentario o explicar brevemente los análisis del ALN.
1. Si se da un problema siempre se debe especificar el estado del mismo.
1. Evitar empezar la retrospectiva de un sprint con los problemas que ha habido durante este.
1. Si falla algo en un sprint, al final del siguiente hacer especial interés en que se ha tenido en cuenta y se ha realizado alguna medida con métricas.
1. Añadir el numero de refinamientos en las IAs.
1. No usar encabezados de “BIENVENIDO A…” con una descripción de los servicios en la aplicación, eso sería contenido de la Landing Page.
1. Evitar moverse demasiado a la hora de realizar la presentación, hay que buscar un punto medio entre energía y serenidad, también en ritmos de presentación.
1. Mostrar los análisis del código en vivo es una buena práctica.
1. A mayor número de clientes los costes de mantenimiento deben subir.
1. Añadir una matriz con el esfuerzo en horas y el rendimiento con nuestra fórmulas y los integrantes en ella.
1. Se debe tener cuidado de no fomentar trabajar menos con la gamificación en el desarrollo.
1. Las funciones listadas con botones queda poco profesional se debe buscar meter gráficas y otras disposiciones.
1. Siempre se deben exponer los problemas que ha habido y se han solucionado, los que están por solucionar y las soluciones propuestas.
1. Si se muestran gráficas se debe como mínimo hacer alguna conclusión de esta.
1. La recepción del feedback de los usuarios pilotos debe ser lo antes posible para poder ejercer los cambios necesarios antes del entregable.



## <a name="_es35wsm2my6q22"></a>**Consideraciones para IT TALENT**
- Usar como Killer Opener ISPP y crear grupos de trabajo para el desarrollo y en la DEMO; “Javi, como coordinador quiere crear un grupo de trabajo con X necesidades y para ello…”.
- Introducir los objetivos de la demo al comienzo del video y poner un icono representando al usuario/representante (yo diría de poner un texto que se vea todo el rato mientras se hable de Candidatos o Representatives)
- El storyboard es poco creíble, un programador de Cobol no debería tener problemas de falta de trabajo.
- Usar más gráficas, “modo resumen” y más visuales, en las estadísticas de GitHub de  los candidatos.
- Dejar más claro el estado de los problemas que ha habido, meter iconografías si estos están solucionados o en proceso de serlo. Con mayor focus en las métricas.
- La planificación del Sprint 3 queda muy escueta.
- Realizar cambios sobre el workflow del feedback de los usuarios pilotos, se debe de ver más claro.
- Añadir el numero de refinamientos necesarios en el report de las IAs.



## <a name="_xw8pcxlaup9y22"></a>**Tareas - ¿Qué no puede faltar?**


- Nueva versión del Failure Conditions
- Hay enlaces para los dashboard de BlueJ (no influye en la nota) pero se puede usar para meterlo en la presentación.


1. **INTRODUCCIÓN**:
   1. Killer opener
   1. Elevator pitch, con un par de frases predefinidas. Recordar que se busca convencer a los inversores.
   1. Análisis de competidores, centrarnos en las features killer y pasar poco por el resto.
1. Storyboards + **ANUNCIO en vivo de uno de ellos**
1. **Impacto Legal** del proyecto
1. **Customer agreement**
   1. Desarrollar Términos de servicios
   1. Uso de Claudette: ¿Qué cláusulas se han eliminado? ¿Cuáles no?
   1. Pricing
   1. SLA: Implicaciones de estas en la implementacion (Cambios en el TCO por personal de soporte adicional por una subida de usuarios)
1. **COSTES**:
   1. TCO a 2 años
   1. Capex vs Opex
   1. Costes GActions
   1. Cuanto llevamos gastado con respecto al Total
   1. Estimaciones pesimistas, optimistas… Con respecto al número de usuarios
1. Refinar **estructura de equipo**:
   1. Estado del Commitment Agreement + Historial de este, ¿Cuándo y por qué no se ha cumplido?
1. **DEMO** dinámica** sprint 3:
   1. **Resaltar** que estaba en el S1 y S2 y que hemos hecho **nuevo** con el resto feedback.
   1. Mejoras de UX (píldora teórica).
   1. Registro con términos y condiciones + Cosas de GDPR implementadas.
   1. Implementación de aspectos legales (P.E: ¿cookies?...) 
1. **RETROSPECTIVA**:
   1. Evolución de la calidad del código, Sonar, Codacy… ver incremento y decremento de métricas.
   1. Rendimiento del equipo, desarrollando las fórmulas.
      1. Matriz de **HORAS vs RENDIMIENTO** con todos los integrantes.
   1. Gráfica de productividad y evolución.
   1. Mejoras de agendamiento y calendario compartido: ¿Cómo y cuánto nos han ayudado?
   1. Plan de pruebas, píldora de testing, planes de aquí al Proyect Launch. 
   1. Gestión de riesgos: **Riesgos** que se han dado + **problemas que no eran riesgos**: Medidas, métricas, planes…
   1. Lecciones Aprendidas
   1. (Reloj de avance de proyecto, clockify semanal y global) ¿breve? - no tengo apuntado que lo dijera, pero igual se le pasó
   1. Changelog (evaluar meterlo en la demo) - Qué se ha incrementado con respecto a la semana anterior.
1. Gestión de **Usuarios Piloto**.
   1. **Gestión del feedback** (demostrar que el usuario está siendo escuchado)
   1. Resumen del feedback proporcionado
   1. ¿Qué prioridad se le ha dado a cada cambio necesario y por qué?
   1. Acciones de consolidación que se han tomado a partir de ese feedback
   1. Desarrollar Commitment Agreement con los usuarios piotos
1. **PLANIFICACIÓN**:
   1. Issues previstas para este sprint + las que ya serán para futuras mejoras (quedan fuera del desarrollo actual)
   1. Objetivos para la demo final.
   1. Objetivos del 3: Registro, Pagos...
   1. Hacer planificación preliminar de la siguiente fase
1. **Uso de IA**
1. QR **landing page**


# <a name="_3n6nqs3ox56d23"></a> Semana 9 (09/04)
## <a name="_4ki1iznv6aw623"></a>**Cosas a tener en cuenta**

1. Cuidar la velocidad con la que se cuenta la información, sobre todo para personas que no conocen la aplicación o nunca han visto la presentación antes. Evaluar si reducir el nivel de detalle/contenido por apartado.
1. Cuidar el formato de la presentación para que se adecúe al aula en la que se va a exponer, si no da la sensación de mala calidez o cutrez.
1. Es crucial añadir indicadores a los problemas que se presenten (si hay colisiones en el frontend, indicar el número).
1. NO añadir información redundante en la DEMO (p.ej: edición de campos o registro).
1. Mencionar primero la fórmula del rendimiento y luego el rendimiento del equipo.
1. Añadir el número total de pruebas que se van a realizar a cada característica.
1. No es necesario comentar los problemas que van bien, sobre todo si hay falta de tiempo o varios que mencionar.
1. Evitar añadir demasiada información que den contexto del proyecto, sobre todo si al mismo tiempo se está exponiendo lo mismo.
1. Hacer un seguimiento de las funcionalidades que los usuarios pilotos consideran más interesantes/importantes. Realizar un orden de estas.
1. Si se añade texto en los anuncios debe haber tiempo suficiente para leerlo o debe ser un texto lo suficientemente breve.
1. No hacer uso de imágenes poco realistas para fotos en la demo, si se usan IAs hacer uso de alguna fotorrealista.
1. Cuidar la escala de gráficas y añadir prefijos como K o M.




## <a name="_es35wsm2my6q23"></a>**Consideraciones para IT TALENT**
- Cuidar la iluminación del anuncio así como la vocalización y velocidad del diálogo.
- ¿SON LOS CORRECTOS USUARIOS POTENCIALES? Hay que cambiar el enfoque, la búsqueda de trabajo es constante
- Añadir diapositivas de apoyo para el Customer Agreement (Diapositiva: SLA + TOS).
- Especificar los datos de la diapositiva Capex vs Opex. Y añadir datos de usuarios empleados que se registrarían en la aplicación.
- Pararse brevemente a explicar qué es cada cláusulas del Commitment Agreement.
- En la DEMO pararse en las funcionalidades core y no mencionar la edición/eliminación de perfiles.
- Al subir el ritmo del diálogo se deja de seguir el ritmo de la presentación y se pierden conceptos.
- Para cada gráfico (a partir de la 37) o dato que se enseñe, prepararse una frase que resuma el gráfico (p.ej: ha habido un aumento del rendimiento del 4%) o plasmarlo en la misma diapositiva.
- La gráfica de rendimiento individual no refleja bien la diferencia con respecto de una semana a otra, si se quiere plasmar eso habría que cambiar la forma de enseñarlo.
- La DEMO debe estar más orientada al  anuncio, que Javi salga en el anuncio como jefe y luego salga igual en la foto de perfil de la DEMO.
- Se debe plasmar si los tests están siendo efectivos o no (inventarse fallos o realizar test que se sabe que van a fallar).
- Añadir el numero de refinamientos necesarios en el report de las IAs.
- Meter acciones de consolidación en la Base de Conocimientos
- Tener un apartado de la DEMO en el Docusaurio (link a Youtube…).
- Añadir apoyo para los SLA y ToS (Customer Agreement)
- Incluir los ToS en el registro.
- Añadir el feedback específico nos han dado los Usuarios Pilotos. A cada feedback que se mencione que han aportado los usuarios piloto añadir la prioridad que se le ha asignado.
- A Muller le gustó que: Para cada problema: OPEN, NOT SOLVED, IN PROGRESS, SOLVED
- Muller mencionó que es buena practica realizar pruebas de carga que muestren cuantás peticiones son necesarias para agotar los créditos de Google.
- A Muller le gustó: Segmentación de mercado de cara al proyect launch (píldora teórica).

## <a name="_xw8pcxlaup9y23"></a>**Tareas - ¿Qué no puede faltar?**


- Nueva versión del Failure Conditions


1. **INTRODUCCIÓN**:
   1. Killer opener
   1. Elevator pitch, con un par de frases predefinidas. Recordar que se busca convencer a los inversores.
   1. Análisis de competidores, centrarnos en las features killer y pasar poco por el resto.
1. Storyboards + **ANUNCIO en vivo de uno de ellos** (Volver a incluirla especificando si se ha modificado algo, también se puede ir añadiendo el siguiente).
1. **Impacto Legal** del proyecto
1. **Customer agreement**
   1. Uso de Claudette: ¿Qué cláusulas se han tenido que modificar? ¿Cómo?
   1. Pricing
   1. ToS
   1. SLA: Implicaciones de estas en la implementacion (Cambios en el TCO por personal de soporte adicional por una subida de usuarios)
1. **Estrategias de marketing** preliminares puntuales:
   1. ¿Qué hacer para ganar tracción en el mercado?: segmentación
   1. ¿A quién nos vamos a enfocar? ¿Cómo vamos a hacer para que se enfoque a ese perfil?
   1. Añadir rol de Community Manager.
1. **COSTES**:
   1. TCO a 2 años
   1. Capex vs Opex
   1. Costes GActions
   1. Cuanto llevamos gastado con respecto al Total
   1. Estimaciones pesimistas, optimistas… Con respecto al número de usuarios
   1. Modificaciones de nuevos roles: GDPR Data Protección Officer y Community Manager
1. Refinar **estructura de equipo**:
   1. Estado del Commitment Agreement + Historial de este, ¿Cuándo y por qué no se ha cumplido?
   1. Modificaciones de nuevos roles: GDPR Data Protección Officer y Community Manager
1. **DEMO** dinámica** sprint 3: **Descripción previa** al video
   1. Si en lo que se muestra hay **algo nuevo, marcarlo** (no quiere decir que haya que mostrar todo lo nuevo)
   1. Destacar **mejoras de UX** (píldora teórica).
   1. Implementación de aspectos legales (P.E: ¿cookies?...)
   1. Registro con términos y condiciones
   1. GDPR Compliance: httpS, derecho de olvido...
1. **RETROSPECTIVA**:
   1. Evolución de la calidad del código, Sonar, Codacy… ver incremento y decremento de métricas.
   1. Rendimiento del equipo, desarrollando las fórmulas.
      1. Matriz de **HORAS vs RENDIMIENTO** con todos los integrantes.
   1. Gráfica de productividad y evolución.
   1. Plan de pruebas, píldora de testing, planes de aquí al Proyect Launch. 
   1. Gestión de riesgos: **Riesgos** que se han dado + **problemas que no eran riesgos**: Medidas, métricas, planes…
   1. Lecciones Aprendidas
   1. Reloj de avance de proyecto, clockify semanal y global
   1. Changelog - Qué se ha incrementado con respecto a la semana anterior.
1. Gestión de **Usuarios Piloto**.
   1. **Gestión del feedback** (demostrar que el usuario está siendo escuchado)
   1. Resumen del feedback proporcionado: **feedback específico** 
   1. ¿Qué **prioridad se le ha dado a cada cambio** necesario y por qué?
   1. Acciones de consolidación que se han tomado a partir de ese feedback
   1. (Desarrollar Commitment Agreement con los usuarios pilotos) creo que poca gente lo ha mencionado y no han dicho nada pero luego en la evaluación nunca se sabe.
1. **PLANIFICACIÓN**: **De este apartado solo dijo "Planificación", no se qué habrá que mencionar, entiendo que algo de las futuras fases, cambio en los equipos...**
   1. Issues previstas para este sprint + las que ya serán para futuras mejoras (quedan fuera del desarrollo actual)
   1. Objetivos para la demo final.
   1. Objetivos del 3: Registro, Pagos...
1. **Uso de IA**
1. QR **landing page**


# <a name="_3n6nqs3ox56d24"></a> Semana 10 (23/04)
## <a name="_4ki1iznv6aw624"></a>**Cosas a tener en cuenta**

1. Evitar hablar de cosas como el GDPR que son generales e iguales para todos y entrar en conceptos de grupo.
1. Justificar siempre por qué se darían datos optimistas o pesimistas.
1. La DEMO debería tener algo parecido a una historia, no debe verse como una lista de funcionalidades. Es buen práctica que el anuncio se vea reflejado en la DEMO.
1. Incluir cómo se van a medir y qué horizontes se van a poner a las métricas para resolver los problemas.
1. Especificar los bugs que se han detectado y de qué manera se han solucionado.
1. Si durante esa semana ha habido algún problema con los usuarios pilotos, se deben desarrollar las acciones que se han tomado con respecto al Acuerdo de los Usuarios Piloto.
1. Por cada riesgo o problema que se presente, debe haber acciones de consolidación, pero lo más importante es que además deben haber métricas y se deben exponer en la presentación. “Vamos a reunirnos cada 2 días” “Vamos a …” Debe haber una métrica para medir el grado de satisfacción de la medida y un umbral que mida cuando se ha solucionado.
1. Cuando se hable de los problemas que han aparecido, reflejar de alguna manera (una tabla es lo más sencillo para que lo vean claro los profesores) que se vea: Problema – Medida – Métrica - Estado 
1. Las presentaciones deben servir de apoyo a la audiencia, no deben parecer apuntes para el orador. Se deben buscar más iconografías e imágenes.
1. Los números realistas deben ser lo suficientemente optimistas como para que sea rentable como para que un equipo pueda mantenerla. Luego estos números se podrán justificar en la campaña de lanzamiento durante los próximos sprints.
1. Si como presentador tenemos problemas de hablar rápido es buena práctica realizar ejercicios de vocalización previos a la presentación.
1. No confundir los términos "beneficios" e "ingresos", sobre todo al reflejarlos en la presentación.
1. Se debe cuidar el uso de conectores durante la presentación sobre todo si no tiene sentido coherente entre ambas frases.
1. Hay que saber medir cuando, aún habiendo mucho esfuerzo en una tarea, si se da una corrección o una recomendación, aceptar estas y realizar algo de retrospectiva en lugar de tratar de defenderla a cualquier costo.
1. No usar canciones demasiado conocidas para los anuncios. Plantearse usar herramientas de IA con el nombre de nuestra aplicación para estos.
1. Se debería de prever con anterioridad a padecer el problema el pasarse de las horas estipuladas en la asignatura. Si ya ha pasado no se ha tratado de manera correcta.
1. Si no se pueden realizar los test de carga sobre el AppEngine es conveniente buscar alternativas, aunque sea probarlo el local y extrapolar al despliegue real.
1. Si alguien disminuye su rendimiento de manera constante es necesario tomar algún tipo de medida, hablarlo con él y llegar a algún tipo de solución para que la tendencia no siga.
1. En los anuncios evitar anuncios de dinámica “¿Conoces la app ...?” Es mejor llegar de una manera más orgánica, en la que uno presente las necesidades que puede satisfacer la aplicación y entonces se le ocurra usar la nuestra.
1. Al recoger el feedback de los usuarios piloto sobre los precios, nos da más información preguntar primero cuánto estaría dispuesto a pagar antes de mostrarle cuánto cuesta.


## <a name="_es35wsm2my6q24"></a>**Consideraciones para IT TALENT**
- Evitar hablar de cosas como el GDPR que son generales e iguales para todos y entrar en conceptos de grupo.
- Justificar mejor por qué se darían datos optimistas o pesimistas.
- La DEMO debería tener algo parecido a una historia, no debe verse como una lista de funcionalidades. Es buen práctica que el anuncio se vea reflejado en la DEMO.
- Quitar decimales de los años de experiencia (son pequeños detalles pero no pueden llegar a la presentación siendo 15 miembros de equipo).
- Incluir cómo se van a medir y qué horizontes se van a poner a las métricas para resolver los problemas.
- Un fondo oscuro es poco práctico, debe como mínimo existir la opción de poner un modo claro. Es difícil leer cosas como la leyenda de los gráficos.
- Dejar claro que la búsqueda de nuevos usuarios pilotos sigue activa.
- Al ser una herramienta que se usaría de forma puntual y de manera no extendida no tiene sentido el fondo oscuro.
- Especificar los bugs que se han detectado y de qué manera se han solucionado.
- Si durante esa semana ha habido algún problema con los usuarios pilotos, se deben desarrollar las acciones que se han tomado con respecto al Acuerdo de los Usuarios Piloto.
- Por cada riesgo o problema que se presente, debe haber acciones de consolidación, pero lo más importante es que además deben haber métricas y se deben exponer en la presentación. “Vamos a reunirnos cada 2 días” “Vamos a …” Debe haber una métrica para medir el grado de satisfacción de la medida y un umbral que mida cuando se ha solucionado.
- Cuando se hable de los problemas que han aparecido, reflejar de alguna manera (una tabla es lo más sencillo para que lo vean claro los profesores) que se vea: Problema – Medida – Métrica - Estado 

## <a name="_xw8pcxlaup9y24"></a>**Tareas - ¿Qué no puede faltar?**


- WPL: 
   - En el salón de actos 21 de mayo. Desde las 12:30  a 14:30
   - Se podrá ensayar el Lunes de 13:30 a 16:30. Preparar temas como el cañón, audio…

HABRÁ 2 PRESENTACIONES distintas:

- **Una de 10 minutos para ensayar el WPL:**

1. ¿De qué va el proyecto?
   1. Killer opener
   1. Elevator pitch
   1. Video usuario/cliente
1. ¿Cómo funciona? - DEMO
1. ¿Hay competencia?
   1. Análisis de competidores
   1. ¿Qué nos diferencia?
1. ¿Quién hay detrás? - Equipo
1. ¿Es rentable?
   1. Planes de precio
   1. Resumen de plan de negocio, costes...
   1. Oportunidades de inversión, ROI
   1. Anuncio de inversores:
      1. ¿Qué podemos ofrecer?
      1. ¿De qué va el proyecto?
      1. Opciones de inversión – “Si invertes X en tanto tiempo conseguirás Y”
1. Landing page, contacto…


- **Otra de 5 minutos sobre la campaña de lanzamiento:**

1. Segmentación del mercado - ¿A quién va dirigido? (modelo de segmentación) (2 perfiles como mínimo)
1. Algún tipo de optimización SEO – Buscadores, palabras claves…
1. Campaña de lanzamiento previo al WPL – Promociones, acciones de impulso para tracción inicial (orientado al cliente más que al usuario)
1. Acciones de marketing
1. Community Management:
   1. Objetivos (Píldora teórica)
   1. Planning (Publicaciones en las RRSS)
   1. Responsables (De las RRSS)
   1. Número de impresiones que tenemos como objetivo
   1. ...
1. Coste de marketing – Desglosado
1. Si hay algún anuncio que queramos poner que no saliera en la primera se pone para comentarlo
1. Uso de las IAs
